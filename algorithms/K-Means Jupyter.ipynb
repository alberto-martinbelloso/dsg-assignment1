{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory assignment - Data Science in Games\n",
    "Implementation of K-Means algorithm by Rasmus Emil Odgaard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#For plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"./\"\n",
    "file = \"fifa.csv\"\n",
    "assert os.path.isdir(f\"{basedir}data\") and os.path.exists(f\"{basedir}data/{file}\"), 'Data not found. Make sure to have the most recent version!'\n",
    "\n",
    "data = pd.read_csv(f'{basedir}/data/fifa.csv', sep=\",\")\n",
    "\n",
    "all_features = ['Crossing','Finishing','HeadingAccuracy','ShortPassing','Volleys','Dribbling','Curve','FKAccuracy','LongPassing',\n",
    "            'BallControl','Acceleration','SprintSpeed','Agility','Reactions','Balance','ShotPower','Jumping','Stamina',\n",
    "            'Strength','LongShots','Aggression','Interceptions','Positioning','Vision','Penalties','Composure',\n",
    "            'Marking','StandingTackle','SlidingTackle','GKDiving','GKHandling','GKKicking','GKPositioning','GKReflexes']\n",
    "\n",
    "features = ['Finishing','SlidingTackle']\n",
    "data = data.dropna(subset=features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_clustering(data, k, max_iter=300):\n",
    "    iter = -1\n",
    "    features = list(data)\n",
    "    centroids = np.random.rand(k,len(features))*100\n",
    "    clust_data = data.copy()    \n",
    "\n",
    "    #for i in range (0,len(features)):\n",
    "    #    clust_data=(clust_data-clust_data.min())/(clust_data.max()-clust_data.min())\n",
    "            \n",
    "    clust_data = clust_data.to_numpy()\n",
    "                \n",
    "    for i in range (0,max_iter):\n",
    "        iter = i\n",
    "        classifications = {}\n",
    "        classification_list = []\n",
    "        \n",
    "        for j in range (k):\n",
    "            classifications[j] = []\n",
    "        \n",
    "        for index, featureset in enumerate(clust_data):\n",
    "            distances = [np.linalg.norm(featureset-centroids[c]) for c in range(k)]\n",
    "            classification = distances.index(min(distances))\n",
    "            classification_list.append(classification)\n",
    "            classifications[classification].append(featureset)\n",
    "            \n",
    "        prev_centroids = np.copy(centroids)    \n",
    "        \n",
    "        for classification in classifications:\n",
    "            if (len(classifications[classification]) > 0):\n",
    "                centroids[classification] = np.average(classifications[classification], axis=0)\n",
    "        \n",
    "        if np.array_equal(prev_centroids, centroids):\n",
    "            data['Centroid'] = classification_list\n",
    "            break\n",
    "        \n",
    "    print('Final iteration: ', iter) \n",
    "    data['Centroid'] = classification_list\n",
    "    return data, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final iteration:  36\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "\n",
    "new_data, new_centroids = k_means_clustering(data[features].head(1000),K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette(X,cluster_labels,n_clusters, centroids,features):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.5, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = centroids\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(features[0])\n",
    "    ax2.set_ylabel(features[1])\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with k = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 3 The average silhouette_score is : 0.6523377916489084\n"
     ]
    }
   ],
   "source": [
    "data_points = new_data.loc[:, features].to_numpy()\n",
    "data_labels = new_data.loc[:,'Centroid'].to_numpy()\n",
    "sns.pairplot(new_data, vars=features, hue='Centroid')\n",
    "silhouette(data_points, data_labels, K, new_centroids, list(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
